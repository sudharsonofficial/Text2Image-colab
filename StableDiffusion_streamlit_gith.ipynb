{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20"
      ],
      "metadata": {
        "id": "AOu5VlP1mFiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXqmbLwCwciY"
      },
      "outputs": [],
      "source": [
        "# Streamlit\n",
        "\n",
        "!pip install google\n",
        "!pip install ngrok\n",
        "!pip install pyngrok\n",
        "!pip install diffusers==0.8.0\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit\n",
        "! pip install pyngrok\n",
        "! pip install streamlit -q\n",
        "# ! pip install --upgrade protobuf\n"
      ],
      "metadata": {
        "id": "c9YT1RSH3cwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stablediffusion\n",
        "%%writefile stablediffusion.py\n",
        "\n",
        "\n",
        "#import os\n",
        "from PIL import Image, ImageDraw\n",
        "#import cv2\n",
        "#import numpy as np\n",
        "#from IPython.display import HTML\n",
        "#from base64 import b64encode\n",
        "#import streamlit as st\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from torch.nn import functional as F\n",
        "from diffusers import StableDiffusionPipeline, AutoencoderKL\n",
        "from diffusers import UNet2DConditionModel, PNDMScheduler, LMSDiscreteScheduler\n",
        "from diffusers.schedulers.scheduling_ddim import DDIMScheduler\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "#from tqdm.auto import tqdm\n",
        "#from huggingface_hub import notebook_login\n",
        "#from google.colab import output\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class stable():\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision='fp16',torch_dtype=torch.float16, use_auth_token=\"#Enter your hugging face token here\")\n",
        "  pipe = pipe.to(device)\n",
        "\n",
        "  def image_grid(self,imgs, rows, cols):\n",
        "      assert len(imgs) == rows*cols\n",
        "\n",
        "      w, h = imgs[0].size\n",
        "      grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "      grid_w, grid_h = grid.size\n",
        "\n",
        "      for i, img in enumerate(imgs):\n",
        "          grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "      return grid\n",
        "\n",
        "  def prompt(self,p):\n",
        "    prompt = p\n",
        "    with autocast(device):\n",
        "      image = self.pipe(prompt)[0]\n",
        "    m=self.image_grid(image,1,1)\n",
        "    st.image(image=m)\n",
        ""
      ],
      "metadata": {
        "id": "iCsuTXVvu3A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from stablediffusion import stable\n",
        "s=stable()\n",
        "st.title('Text to image')\n",
        "p=st.text_input('Enter your text here')\n",
        "st.button(\"Generate\",on_click=s.prompt(p))\n"
      ],
      "metadata": {
        "id": "hMfqJpfzjhbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "66VLrM0Wharf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit\n",
        "from pyngrok import ngrok\n"
      ],
      "metadata": {
        "id": "8Evg4DZ5jWaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit\n",
        "ngrok.set_auth_token(\"#Enter your ngrok authtoken here\") #ngrok.com"
      ],
      "metadata": {
        "id": "ce1MG2IXjZqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlit\n",
        "!nohup streamlit run app.py --server.port 80 &\n",
        "url = ngrok.connect(port = '80')\n",
        "print(url)\n"
      ],
      "metadata": {
        "id": "tTi8AVjKjcWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from pyngrok import ngrok\n",
        "# tunnels = ngrok.get_tunnels()\n",
        "# tunnels\n",
        "# try:\n",
        "#    ngrok_process.proc.wait()\n",
        "# except KeyboardInterrupt:\n",
        "#     print(\" Shutting down server.\")\n",
        "\n",
        "\n",
        "# ngrok.kill() if any issues occur ,try to run this line to troubleshoot"
      ],
      "metadata": {
        "id": "s-2wnr0flVnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 80"
      ],
      "metadata": {
        "id": "Cn9b3t_An-3d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}